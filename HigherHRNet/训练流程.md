tools/dist_train.py

main函数中有各种设置。
主要与流程相关的就是最后部分：是否采用分布式训练，若采用则调用多个main_worker函数；单卡训练则调用一次main_worker函数。
main_worker可以看作时整个训练流程的入口。

1、首先对各种参数进行解析，根据输入参数对魔忍的cfg配置进行更新（默认的配置在lib/config/default.py中，然后通过experiments文件夹下的yaml
   文件更新配置参数）

2、然后检测是否采用分布式训练（没有采用，则直接调用main_worker函数）

/// 下面就是对main_worker函数流程的分析

1、首先，关于cudnn的设置，以及cfg的更新，一个很常用的固定模式，没什么和算法相关的

2、创建model，等同于直接调用lib/models/pose_higher_hrnet.py的get_pose_net()函数
    首先调用get_pose_net()；
    然后执行model = PoseHigherResolutionNet(cfg, **kwargs) 创建model实例；
    最后再初始化权重init_weights。

3、一系列设置，包括日志，model的属性，以及多卡、单卡、GPU的选择

4、设置损失函数。调用了lib/core/loss.py的MultiLossFactory()函数，里面定义了热图损失函数和分组损失函数

5、生成训练数据，也就是训练数据的生成模块，在main_worker中只是一个简单的调用，但这之后有着这个源码最复杂的调用关系。
    我们来复现一下如何生成训练数据的：
    （1）、首先调用lib/dataset/build.py的make_dataloader()，也就是生成训练数据模块的主函数。
    （2）、调用到同文件下的build_dataset()函数，主要输出各种生成器，然后在这个函数中调用了lib/transforms/build.py下的build_transforms()函数，
            build_transforms主要就是设置一些图像增强的生成器。
    （3）、然后接着继续build_dataset()的流程，接下来调用到了lib/dataset/target_generators/target_generators.py的
            HeatmapGenerator()和ScaleAwareHeatmapGenerator()热图生成函数。
    （4）、然后我们接着继续build_dataset()的流程，接下来调用到了lib/dataset/target_generators/target_generators.py的JointsGenerator()关键点生成器
    （5）、然后我们接着继续build_dataset()的流程，接下来调用到了lib/dataset/COCOKeypoints.py(假设使用COCO数据集)。同时传入之前几步所创建的热图生成器，
            关键点生成器和图像增强的生成器。创建CocoKeypoints的实例并进行初始化。 同时，也初始化了其父类CocoDataset。
    （6）、build_dataset()最后返回了一个CocoKeypoints的实例dataset。 然后在make_dataloader()中调用torch.utils.data.DataLoader生成data_loader。
            最后返回data_loader。
    所有调用流程如下：
    main_worker()   # 用于生成训练数据集   # tools/dist_train.py中 
    {
        make_dataloader()   # 生成训练数据模块的主函数  # lib/dataset/bulid.py中
        {
            build_dataset() # 同文件中
            {
                build_transforms()  # 图像增强    # lib/transforms/build.py中
                HeatmapGenerator()  # 生成热图    # lib/dataset/target_generators/target_generators.py中
                或 ScaleAwareHeatmapGenerator() # 生成热力图    # lib/dataset/target_generators/target_generators.py中
                JointsGenerator()   # 生成关键点               # lib/dataset/target_generators/target_generators.py中
                创建COCOKeypoints类的实例     # lib/dataset/COCOKeypoints.py
                return dataset
            }
        }
        data_loader = torch.utils.data.DataLoader(dataset, xxx)
        return data_loader
    }

6、实例化优化器。然后继续main_worker函数，接下来就是定义优化器，作者采用adam优化器。

7、训练前的设置部分

8、训练部分。然后继续main_worker函数。 关键部分就是调用了lib/core/trainer.py的do_train()函数。
    do_train()函数内实现了输入数据，返回检测后的结果，并进行损失函数计算，更新参数。
    do_train()函数后就是更新最优模型，若该epoch是最优模型，则会保存此epoch的节点和模型参数。 
    接下来简单介绍一下do_train()函数内的调用流程：
    （1）、首先设置了一些参数后，开始根据我们设置的batch来迭代，执行下面一行语句，会触发之前实例化的dataset的一个函数_getitem_()
        for i, (images, heatmaps, masks, joints) in enumerate(data_loader):
        在CocoKeypoints中可以找到，在enumerate枚举时会触发。
        调用CocoKeypoints的__getitem__()同时也会调用父类CocoDataset的__getitem__()
        最终CocoKeypoint的__getitem__()会返回4个返回值: img, target_list, mask_list, joints_list就是对应着trainer.py中的(images, heatmaps, masks, joints)
    （2）、执行model的forward函数进行推理，输入的数据根据model的计算最后得到结果。
    （3）、计算损失。loss_factory实际上就是之前提到的MultiLossFactory函数。这里实际上在执行MultiLossFactory的forward函数。
            最后再对损失函数进行一个综合计算，得出总损失值。
    （4）、更新参数    optimizer.step()
    （5）、输出打印信息
    （6）、输出日志并保存相关文件
    


    
    



